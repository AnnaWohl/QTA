{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import codecs, nltk, string, os, gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "# this represent any text as a single \"doc-embedding\" we use it both for the query and the sentences\n",
    "# input should be a string\n",
    "def text_embedding(text):\n",
    "    \n",
    "    #you should check in the embeddings you use if the words have been lowercased or not. \n",
    "    #try ask the embedding for \"barack\" and for \"Barack\"\n",
    "    # if the Barack works, then comment the following line\n",
    "    text = text.lower()\n",
    "    \n",
    "    # we tokenize the text in single words\n",
    "    text = nltk.tokenize.WordPunctTokenizer().tokenize(text)\n",
    "    \n",
    "    # we remove numbers and punctuation\n",
    "    text = [token for token in text if token not in exclude and token.isalpha()]\n",
    "    \n",
    "    \n",
    "    doc_embed = []\n",
    "    \n",
    "    # for each word we get the embedding and we append it to a list\n",
    "    for word in text:\n",
    "            try:\n",
    "                embed_word = emb_model[word]\n",
    "                doc_embed.append(embed_word)\n",
    "            except KeyError:\n",
    "                continue\n",
    "    # we average the embeddings of all the words, getting an overall doc embedding\n",
    "    if len(doc_embed)>0:\n",
    "        avg = [float(sum(col))/len(col) for col in zip(*doc_embed)]\n",
    "\n",
    "        avg = np.array(avg).reshape(1, -1)\n",
    "\n",
    "        # the output is a doc-embedding\n",
    "        return avg\n",
    "    else:\n",
    "        return \"Empty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import here your word-embeddings - put the path to the file (if it's .bin change the binary to True)\n",
    "#emb_model = gensim.models.KeyedVectors.load_word2vec_format('../../resources/small-embeddings.txt', binary=False)\n",
    "\n",
    "# german wikipedia from https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\n",
    "#emb_model = gensim.models.KeyedVectors.load_word2vec_format('/Users/federiconanni/Downloads/wiki.de.vec', binary=False)\n",
    "#emb_model = gensim.models.KeyedVectors.load_word2vec_format('C:/Users/Dr. J/Desktop/wiki.de.vec', binary=False)\n",
    "\n",
    "# switch for in-domain \n",
    "emb_model = gensim.models.KeyedVectors.load_word2vec_format('C:/QTA/topic-detect/in-domain-embeddings.txt', binary=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this can be a list of words on the same fine-grained topic, like \"people\", \"elites\"\n",
    "# add more words after a space to make it more precise\n",
    "# query = \"volk bürger\"\n",
    "\n",
    "#focus on \"key key\" terms based on dictionary, let the embeddings find more \n",
    "#query = \"volk\"\n",
    "#query = \"bürger einbürgerung steuerzahler gemeinschaft\"\n",
    "#query = \"elite politiker establishment herrschend\"\n",
    "#query = \"korruption täuschung betrügen verrat schämen skandal wahrheit unehrlich lüge\"\n",
    "#query = \"verantwortung glaubwürdigkeit\"\n",
    "#query = \"souverän neutral\"\n",
    "#query = \"demokratisch referendum volksabstimmung volksinitiative\"\n",
    "#query = \"konsens kompromiss\"\n",
    "#query = \"repräsentation parlament regierung \"\n",
    "query = \"populisten populismus demagogisch demagogen\"\n",
    "\n",
    "# populism at its best?\n",
    "# query = \"volk elite souverän\"\n",
    "\n",
    "query_emb = text_embedding(query)\n",
    "\n",
    "# add the path to the folder where you have your manifestos as text documents\n",
    "# collection_path = \"C:/Users/Dr. J/Dropbox/sparserhetoric/deu2017/\"\n",
    "\n",
    "# only Germany for less output \n",
    "collection_path = \"C:/Users/Dr. J/Dropbox/sparserhetoric/germany17/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be a dictionary of documents, for example manifestos, divided in sentences, which are represented as sentence embeddings\n",
    "collection = {}\n",
    "\n",
    "# you loop over the folder\n",
    "for filename in os.listdir(collection_path):\n",
    "    # you open each file\n",
    "    # note encoding \n",
    "    content = codecs.open(collection_path+filename,\"r\",\"utf-8\").read()\n",
    "    # you split it in sentences\n",
    "    content = nltk.sent_tokenize(content)\n",
    "    \n",
    "    # you represent each sentence in each document as a word-embedding, which captures the meaning of the sentence\n",
    "    content = [[sent, text_embedding(sent)] for sent in content if type(text_embedding(sent))!= str]\n",
    "    collection[filename] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_afd.txt\n",
      "Einer Diffamierung rationaler Religionskritik als „Islamophobie“ oder „Rassismus“ tritt die AfD entgegen. 0.4664059701618274\n",
      "„Politisch korrekte“ Sprachvorgaben lehnen wir entschieden ab, weil sie einer natürlichen Sprachentwicklung entgegenstehen und die Meinungsfreiheit einengen. 0.4162780357149512\n",
      "1 Nr. 0.38847293072751815\n",
      "2 Nr. 0.38847293072751815\n",
      "Echt alternativ. 0.38830717279781835\n",
      "Wir wenden uns gegen die negativen Auswirkungen eines weltweiten Preisdumpings zulasten von Umwelt, Mensch und Tier. 0.388166654541812\n",
      "Die Auswahl des Kandidaten findet hinter verschlossenen Türen durch Absprachen der Parteien statt. 0.38108712664605504\n",
      "2 TierSchG. 0.38031686262262654\n",
      "2 GG). 0.3704120915427453\n",
      "Mit einem freiheitlichen Rechtsstaat sind solche Kontrollmöglichkeiten nicht vereinbar. 0.36259301290236656\n",
      " \n",
      "\n",
      "de_cdu.txt\n",
      "Den Missbrauch des Islam für Hass, Gewalt, Terrorismus und Unterdrückung\n",
      "lehnen wir gemeinsam mit allen friedlichen Muslimen ab und akzeptieren ihn\n",
      "nicht. 0.4882836908159615\n",
      "Seitdem gab es zwischen EU-Mitgliedstaaten keinen\n",
      "einzigen Krieg, keinen einzigen Ausbruch von Gewalt. 0.4839585875788995\n",
      "In\n",
      "Deutschland darf kein Platz für Antisemitismus, Fremdenfeindlichkeit,\n",
      "Ausländerhass, Intoleranz oder Diskriminierung sein. 0.47005468884896423\n",
      "Menschenrechte werden mit Füßen getreten, Rechtsstaatlichkeit missachtet, Meinungs- und Pressefreiheit bedroht. 0.45356828206050354\n",
      "Wer unsere demokratische Grundordnung bekämpft, das Existenzrecht\n",
      "Israels ablehnt, den inneren Frieden gefährdet oder gegen Recht und Gesetz\n",
      "verstößt, muss mit der ganzen Härte unseres Rechtsstaates rechnen. 0.41314564103583884\n",
      "Wir sind Teil der internationalen\n",
      "Allianz im weltweiten Kampf gegen den Terrorismus, Organisierte Kriminalität, Drogenhandel und gegen neue Bedrohungen im Internet. 0.39234937785409535\n",
      "Ein patriotisches\n",
      "Bekenntnis, das niemanden ausschließt und sich gegen niemanden richtet. 0.3877026176643008\n",
      "Wir lehnen vorgefertigte Ideologien und\n",
      "Feindbilder ab. 0.3798955018480191\n",
      "Entwicklungszusammenarbeit und Menschenrechte –\n",
      "Marshall-Plan mit Afrika\n",
      "Millionen Menschen leben in den ärmsten Ländern dieser Welt, oftmals konkret\n",
      "bedroht durch Klimawandel, Bürgerkriege, schlechte Regierungen oder Terror. 0.3684048118324855\n",
      "September beide Stimmen\n",
      "CDU und CSU. 0.36755277027562416\n",
      " \n",
      "\n",
      "de_spd.txt\n",
      "Bei den Austrittsverhandlungen mit Großbritannien gibt es kein\n",
      "„Europa à la carte“. 0.5858313794069718\n",
      "Leben frei von Gewalt und Diskriminierung:\n",
      "Wir kämpfen gegen jede Form menschenverachtenden Verhaltens und gegen Gewalt. 0.4799269107280263\n",
      "Wir wenden uns allerdings\n",
      "entschieden gegen völlig unnötige und unrealistische Steigerungsraten des deutschen\n",
      "Verteidigungshaushaltes. 0.47903787608769494\n",
      "Sozialdemokratinnen und Sozialdemokraten kämpfen seit\n",
      "über 150 Jahren für Toleranz und gegen Rassismus, Rechtsextremismus, Diskriminierung und\n",
      "Menschenfeindlichkeit. 0.4576552826105831\n",
      "Keine Toleranz gegenüber\n",
      "Sozialdumping. 0.40717424527083523\n",
      "Steuerbetrug bekämpfen:\n",
      "Steuerbetrug ist kriminell. 0.3990478024846763\n",
      "Aufrüstung und Säbelrasseln lösen keine Konflikte. 0.3885651363347741\n",
      "Wir nehmen auch Gewalt gegen Männer sehr ernst. 0.3816516577426299\n",
      "Nationale Alleingänge und Protektionismus versprechen\n",
      "keinen Erfolg. 0.37763616061992705\n",
      "Deshalb werden\n",
      "wir konsequent mit allen rechtsstaatlichen Mitteln gegen Terror und extremistische Gewalt\n",
      "vorgehen. 0.3770828894403385\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now, the information retrieval part\n",
    "\n",
    "for filename,sentences in collection.items():\n",
    "    \n",
    "    # compare the cosine similarity between the embedding of the query and each sentence embedding\n",
    "    ranking = [[sent, cosine_similarity(query_emb,sent_emb)[0][0]] for sent, sent_emb in sentences]\n",
    "    # you rank them, based on the similarity\n",
    "    ranking.sort(key=lambda x: x[1],reverse=True)\n",
    "    \n",
    "    print (filename)\n",
    "    # you can change here for having more sentences as output\n",
    "    for sent, score in ranking[:10]:\n",
    "        print (sent, score)\n",
    "    print (\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
